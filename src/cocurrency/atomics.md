
### 数据访问
C++ 内存模型试图通过允许我们谈论我们程序的因果性来弥补这一差距。一般来说，这是通过在程序的各个部分和运行它们的线程之间建立一种happen-before的关系。这给了硬件和编译器一定的自由度，在没有建立严格的 happen-before 关系的地方更积极地优化程序，但也迫使他们在建立了关系的地方更加小心。我们沟通这些关系的方式是通过数据访问（data accesses）和原子访问（atomic accesses）。

数据访问是编程世界的主体，它们从根本上说是不同步的，编译器可以自由地对它们进行积极的优化。特别是，数据访问可以自由地被编译器重新排序，前提是程序是单线程的。硬件也可以自由地将数据访问中的变化传播给其他线程，只要它想，就可以懒散地、不一致地传播。最关键的是，数据访问是数据竞争发生的方式。数据访问对硬件和编译器非常友好，但正如我们所看到的，如果试图用它来编写同步代码，它提供的语义太弱了。

仅仅使用数据访问是不可能写出正确的同步代码的。

原子访问是我们告诉硬件和编译器我们的程序是多线程的方式。每个原子访问都可以用一个顺序来标记，指定它与其他访问的关系。在实践中，这可以归结为告诉编译器和硬件它们不能做的某些事情。对于编译器来说，这主要是围绕着指令的重新排序展开的。对于硬件来说，这主要是围绕着如何将写操作传播给其他线程。Rust 所提供的顺序集合是：

- 顺序一致（Squentially Consistent，SeqCst）
 - Release
 - Acquire
 - Relaxed

 ```rust
initial state: X = 0, Y = 1
 
THREAD Main     THREAD A
X = 1;          if X == 1 {
Y = 3;              Y *= 2;
X = 2;          }
 ```
理想的情况下，Y最终可能的值为：
- Y = 3：THREAD A运行完后才运行THREAD Main。或是THREAD Main运行完后才运行THREAD A。
- Y = 6：THREAD Main运行完Y = 3后，运行THREAD A。THREAD A运行完后，THREAD Main才继续运行完。

而实际上我们却有可能会得到以下这种状态：
- Y = 2：THREAD Main正在运行Y = 3，THREAD A此时也开始运行Y *= 2。3这个值来不及回存到Y，Y就被Y *= 2先行取用了(此时取到的Y为1)，而当3这个值终于回存到Y后，Y *= 2才计算完成，所以Y的值变成2。

上述只是一般的竞跑，更极端一点由CPU缓存引起的内存顺序问题还有以下这个：
- Y = 2：THREAD Main虽然已经确实运行完Y = 3了，但是该CPU缓存中的Y = 3还没同步到其它CPU的缓存中，此时THREAD A的Y *= 2就开始读取Y，因此它读到的Y值为1，计算之后就出现Y = 2的结果。

甚至即便改成：
```rust 
initial state: X = 0, Y = 1
 
THREAD Main     THREAD A
X = 1;          if X == 2 {
Y = 3;              Y *= 2;
X = 2;          }
```
也还是可能会出现Y = 2的情形，因为X和Y被同步至其它CPU的缓存中的顺序不一。

### 顺序一致性 (SeqCst)
顺序一致是所有顺序中最强大的，它意味着包含所有其他顺序的限制。直观地说，一个顺序一致的操作不能被重新排序：一个线程上所有发生在 SeqCst 访问之前和之后的访问都保持在它之前和之后。一个只使用顺序一致的原子和数据访问的无数据竞争程序有一个非常好的特性，即有一个所有线程都同意的程序指令的单一全局执行的顺序。这种执行方式也特别好推理：它只是每个线程的单独执行的交错。如果你开始使用较弱的原子顺序，这就不成立了（译者注：也就是说，同一时刻，针对同一个别名/内存位置，仅能有一条指令在执行，不能出现并发）。

直观地说，一个 Acquire 的访问可以确保它之后的每一个访问都保持在它之后。然而，在 Acquire 之前发生的操作可以自由地被重新排序到它之后发生。同样地，一个 Release 访问确保它之前的每一个访问都保持在它之前。然而，在 Release 之后发生的操作可以自由地被重新排序到它之前发生。

### Acquire-Release

当线程 A Release 了内存中的一个位置，然后线程 B 随后 Acquire 了内存中相同的位置，因果关系就建立了。在 A Release 之前发生的每一个写（对同一个内存位置的写，包括非原子写和 Relaxed 的原子写）都会在 B Acquire 之后被观察到。然而，与任何其他线程的因果关系都没有建立。同样地，如果 A 和 B 访问内存中不同的位置，也不会建立因果关系。

因此，Release-Acquire 的基本用法很简单：你 Acquire 一个内存位置来开始关键部分，然后 Release 这个位置来结束它。例如，一个简单的自旋锁可能看起来像这样：

(多线程之间的关系是什么？)

- Memory Ordering
这里我暂时不会提及特别多关于内存模型的知识点，因为这个后面会花大篇幅来详细聊聊到底什么是内存模型。这里我会用最简单的例子来解释一下这个概念。
假设现在有两个线程，一个线程进行读操作，另一个线程进行写操作，而操作的数据是`AtomicBool`类型。这个数据的初始数据是`false`，进行写操作的线程想把这个值改成`true`。现在写操作已经执完了，那么进行读操作的线程是否一定读到的是`true`呢？
答案是否定的，因为写操作刚执行完的时候，最新的数据还存在于CPU的寄存器当中，还没有正式写到内存中（当然这个得基于编译器的实现以及CPU的具体优化策略），因此，非常有可能当写线程执行完了，也就是其对应的汇编已经执行完了，但是最新的数据却还仅仅存在于寄存器当中（针对的是物理多核的CPU）。
那么，我们怎么保证当最新的数据只要出现在寄存器中，就立马同步到内存中呢，这就是Memory Ordering的作用。我们现在只要记住，当我们用原子类的`set()`方法，提供的内存顺序是`Release`参数，在`load()`的时候，提供的内存顺序是`Acquire`参数，就可以保证进行读的线程，读到的一定是寄存器里面最新的值。换句话说，我们可以暂时这样理解，`Release`是将寄存器里面的值和内存的值同步，`Acquire`是忘记自己当前寄存器的值，而直接去内存里面读取最新的值。如果对这一段解释还是感到困惑，就先暂时记住：对于原子类的操作，如果是写，那么内存顺序用Release，如果是读，那么内存顺序用Acquire。

```rust
use std::sync::Arc;
use std::sync::atomic::{AtomicBool, Ordering};
use std::thread;

fn main() {
    let lock = Arc::new(AtomicBool::new(false)); // 我上锁了吗

    // ... 用某种方式将锁分发到各个线程(thread::spawn) ...

    // 尝试将原子变量设置为 true，以此来获得锁
    while lock.compare_and_swap(false, true, Ordering::Acquire) { }
    // 从循环中跳出，说明此时已经获取了锁

    // ... 恐怖的数据访问 ...

    // 工作完成了，释放锁
    lock.store(false, Ordering::Release);
}
```

### Relaxed
Relaxed 的访问是绝对最弱的。它们可以被自由地重新排序，并且不提供任何 happen-before 的关系。不过，Relaxed 的操作仍然是原子性的。也就是说，它们不算是数据访问，对它们进行的任何读-改-写操作都是原子性的。Relaxed 操作适用于那些你肯定希望发生，但并不特别在意的事情。例如，如果你不使用计数器来同步任何其他访问，那么多个线程可以安全地使用 Relaxed 的fetch_add来增加一个计数器。

在强有序平台上，Relaxed 操作很少有好处，因为它们通常提供 Release-Acquire 的语义。然而，在弱有序平台上，Relaxed 的操作会更便宜。